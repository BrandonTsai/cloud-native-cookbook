Refer: https://geekflare.com/docker-architecture/

Container vs Virtual Machine
-------------------------------

![VM-vs-Docker](https://geekflare.com/wp-content/uploads/2019/09/traditional-vs-new-gen.png "VM-vs-Docker")


When it comes to cloud infrastructure, the virtual machine has been the go-to standard for many of its advantages.  However, what if you had an alternative to a virtual machine that was more lightweight, economical, and scalable. That’s precisely what Docker is.

In this blog post, I will explain the basic concept of Docker and the usage of Docker CLI.


Docker Concept
--------------

![Docker Concept](images/01_docker/Docker_concept.png "Docker Concept")

The container’s system requires an underlying operating system that provides the basic services to all of the containerized applications using virtual-memory support for isolation. Docker contains follow components.

**Docker Engine**

It is the core part of the whole Docker system. Docker Engine is an application which follows client-server architecture. It is installed on the host machine.

**Image**

A Docker image is a file, comprised of multiple layers, that is used to execute code in a Docker container. An image is essentially built from the instructions for a complete and executable version of an application, which relies on the host OS kernel. When the Docker user runs an image, it can become one or multiple instances of that container.

**Dockerfile**
A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image. User can use Dockerfile to build customize Docker image


**Container Image Registry**

A registry is a storage and content delivery system, holding named Docker images, available in different tagged versions. The most popular registry is [Docker Hub](https://hub.docker.com/)


**Container**

After you run a docker image, it creates a docker container. All the applications and their environment run inside this container. You can use Docker API or CLI to start, stop, delete a docker container.




How to install docker on RedHat System
---------------------------------------

Very simple, just do yum install

```
sudo yum install docker
```

Notice that Red Hat does not support the latest version of Docker anymore, Podman is suggested to replace Docker since it is considered more secure than Docker. However, you still can install the community version of Docker on RHEL7. Please refer [here](https://computingforgeeks.com/install-docker-ce-on-rhel-7-linux/) to install docker-ce on your RHEL 7 system.


Running Docker Container
-----------------------

In this section, I will introduce the basic usage of docker CLI.
Before running a container, you need to pull the image from Container Registry.

```
sudo docker pull registry.redhat.io/rhscl/postgresql-10-rhel7:1
```

Make sure image exist on your localhost.

```
sudo docker images
```

Following is a standard shell script to run a container on the server.

```
#!/bin/bash

data_folder="/opt/postgresql"
pgsql_user="myadmin"
pgsql_password="myPassword"
pgsql_database="myapp"


sudo mkdir -p ${data_folder}
sudo chmod 777 ${data_folder}

sudo docker run -d --name postgresql \
-e POSTGRESQL_USER="${pgsql_user}" \
-e POSTGRESQL_PASSWORD="${pgsql_password}" \
-e POSTGRESQL_DATABASE="${pgsql_database}" \
-v "${data_folder}:/var/lib/pgsql/data:Z" \
-p "5432:5432" \
registry.redhat.io/rhscl/postgresql-10-rhel7:1
```


### Environment Variables

You can use the ``-e``, or ``--env-file`` flags to set simple (non-array) environment variables in the container, or overwrite variables that are defined in the Dockerfile of the image you’re running.


```
docker run \
-e TZ="${cluster_timezone}" \
-e POSTGRESQL_USER="${pgsql_user}" \
-e POSTGRESQL_PASSWORD="${pgsql_password}" \
-e POSTGRESQL_DATABASE="${pgsql_database}" \
...
```

### Volumes

Volume is used for persisting data generated by and used by Docker containers.
Use ``-v/--volume`` flag to mount the host folder into container.

```
docker run \
-v /host_folder:/opt/config:ro \
...
```

Notice that you must make sure the user inside container has permission to access the mounted host folder. There are two ways to achieve this:

(1) chown -R "uid:gid" /host_folder (recommend)
(2) chmod -R 777 /host_folder


### Expose and Publish


The EXPOSE instruction in Dockerfile informs Docker that the container listens on the specified network ports at runtime.


```
EXPOSE 5432/tcp
```

If you EXPOSE a port, the service in the container is not accessible from outside Docker, but from inside other Docker containers.
Use the -p flag to actually publish the port, the service in the container is accessible from anywhere, even outside Docker.


```BASH
docker run -p "5432:5432" ...
docker run -p "127.0.0.1:8080:80
```

### ENTRYPOINT & CMD


Why set up environment variables can create the database?  -> ENTRYPOINT and CMD


ENTRYPOINT is used to identify which executable should be run when a container is started
The CMD is run via the entrypoint.

If ENTRYPOINT is not specify, the default entrypoint is "/bin/sh -c" or "exec"


```BASH
# exec form, preferred
CMD ["executable","param1","param2"]

# shell form, the <command> will execute in /bin/sh -c
CMD command param1 param2
```


If you would like your container to run the same executable every time,
then you should consider using ENTRYPOINT in combination with CMD

```
ENTRYPOINT /my_container_entrypoint.sh
CMD ["param1", "param2"]
```


> Tips: What is the entrypoint of a container image?
> ```
> sudo docker inspect registry.redhat.io/ubi7/nodejs-12:1
> ```


Docker Exec
-----------

The docker exec command can let user runs a new command in a running container. We could use this command to get into the running container and check the files and service status inside the container. For example,

```
docker exec -it postgresql bash
```


Conclusion
-----------

Overall, Docker allows applications to be packaged with all the dependencies inside, which simplifies the deployment process quite a bit and you get to have full reproducible environments.
Hopefully, this blog served its purpose of getting you excited about containers so that you no longer have to watch the action from the sides.














